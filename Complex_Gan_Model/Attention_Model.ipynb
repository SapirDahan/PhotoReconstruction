{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Attention-Based Image Reconstruction Model\n",
    "\n",
    "This file implements an attention-based deep learning model for image reconstruction. It includes:\n",
    "\n",
    "- Model definition with spatial and channel attention mechanisms.\n",
    "- Custom loss function combining MSE and MAE.\n",
    "- Training and evaluation loops to measure model performance.\n",
    "- Utilities for visualization, pixel replacement, and saving the model.\n",
    "\n",
    "The code is designed to efficiently train and evaluate the model on masked and original images, with support for GPU acceleration."
   ],
   "id": "e27a83aa83f809b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Import Required Libraries\n",
    "\n",
    "This block initializes the project environment, ensuring necessary libraries and configurations are in place."
   ],
   "id": "e034d26d4a3e7a0f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-01T11:59:09.387459Z",
     "start_time": "2025-01-01T11:59:05.944385Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import dill\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*cudnnException.*\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Define Dataset Class\n",
    "We create a custom dataset class to load pairs of original and masked images. The images are assumed to have the same name, with `_masked` appended to the masked image files."
   ],
   "id": "cc224d437027324d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T11:59:09.444528Z",
     "start_time": "2025-01-01T11:59:09.396432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImageMaskDataset(Dataset):\n",
    " \n",
    "    def __init__(self, directory, transform=None, augment=False):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.image_files = [f for f in os.listdir(directory) if not f.endswith(\"_masked.jpg\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_name = self.image_files[idx]\n",
    "        masked_name = original_name.replace(\".jpg\", \"_masked.jpg\")\n",
    "\n",
    "        original_path = os.path.join(self.directory, original_name)\n",
    "        masked_path = os.path.join(self.directory, masked_name)\n",
    "\n",
    "        # Load images\n",
    "        original_img = Image.open(original_path).convert(\"RGB\")\n",
    "        masked_img = Image.open(masked_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply augmentations if enabled\n",
    "        if self.augment:\n",
    "            # Random Horizontal Flip\n",
    "            if random.random() > 0.5:\n",
    "                original_img = TF.hflip(original_img)\n",
    "                masked_img = TF.hflip(masked_img)\n",
    "\n",
    "            # Random Rotation\n",
    "            angle = random.uniform(-30, 30)  # Reduce rotation range for subtle changes\n",
    "            original_img = TF.rotate(original_img, angle)\n",
    "            masked_img = TF.rotate(masked_img, angle)\n",
    "\n",
    "            # Random Crop with Padding\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(original_img, output_size=(224, 224))\n",
    "            original_img = TF.crop(original_img, i, j, h, w)\n",
    "            masked_img = TF.crop(masked_img, i, j, h, w)\n",
    "\n",
    "        # Apply basic transformations (e.g., ToTensor, normalization)\n",
    "        if self.transform:\n",
    "            original_img = self.transform(original_img)\n",
    "            masked_img = self.transform(masked_img)\n",
    "\n",
    "        return masked_img, original_img\n",
    "\n",
    "# Define transformations to normalize image pixels to [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to tensors (auto-normalized to [0, 1])\n",
    "])\n",
    "\n",
    "# Base directory for the dataset\n",
    "base_dir = os.path.join(\"..\", \"Dataset\")\n",
    "\n",
    "# Directories for train, validation, and test sets\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"validation\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# Initialize datasets\n",
    "train_dataset = ImageMaskDataset(train_dir, transform=transform, augment=True)  # Enable augmentation for training\n",
    "val_dataset = ImageMaskDataset(val_dir, transform=transform, augment=False)     # No augmentation for validation\n",
    "test_dataset = ImageMaskDataset(test_dir, transform=transform, augment=False)   # No augmentation for testing\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Verify dataset sizes and loader functionality\n",
    "print(f\"Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n"
   ],
   "id": "8204521f62011eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 9440, Validation samples: 1350, Test samples: 2710\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## The Model with Attention Mechanisms\n",
    "\n",
    "This block defines a custom image reconstruction model incorporating attention mechanisms (spatial and channel attention) and residual connections. The architecture is designed to enhance feature representation and improve the quality of image reconstruction. Below are the main components and their roles:\n",
    "\n",
    "### 1. ResidualBlock\n",
    "- **Purpose**: Implements residual connections to ease the training of deep networks by enabling gradient flow and addressing the vanishing gradient problem.\n",
    "- **Details**: Consists of two convolutional layers with Batch Normalization and a ReLU activation function. The input is added to the output to form a residual connection.\n",
    "\n",
    "### 2. ChannelAttention\n",
    "- **Purpose**: Focuses on enhancing important channels in the feature map while suppressing less relevant ones.\n",
    "- **Details**: Utilizes global average pooling followed by two fully connected layers and a Sigmoid activation to generate channel-wise attention weights.\n",
    "\n",
    "### 3. SpatialAttention\n",
    "- **Purpose**: Emphasizes important spatial regions in the feature map by analyzing the spatial context.\n",
    "- **Details**: Takes the mean and max across channels, concatenates them, and applies a convolutional layer followed by a Sigmoid activation to generate spatial attention weights.\n",
    "\n",
    "### 4. ImageReconstructionModel\n",
    "- **Structure**: Composed of three main parts: Encoder, Bottleneck, and Decoder.\n",
    "  - **Encoder**: Extracts features from the input image at multiple scales using convolutional layers, attention mechanisms, and downsampling.\n",
    "    - `encoder1`: First encoding stage with spatial attention and dropout for regularization.\n",
    "    - `encoder2` & `encoder3`: Subsequent encoding stages with channel attention for enhanced feature representation.\n",
    "  - **Bottleneck**: Utilizes residual blocks to refine features while maintaining the scale.\n",
    "  - **Decoder**: Reconstructs the image using upsampling and residual blocks while incorporating skip connections.\n",
    "    - `decoder1` & `decoder2`: Reconstruct intermediate features with spatial attention and PixelShuffle for upsampling.\n",
    "    - `decoder3`: Final reconstruction with normalization using Sigmoid activation.\n",
    "  - **Skip Connections**: Pass features from the encoder to the decoder, ensuring information retention at multiple scales.\n",
    "    - `skip1` & `skip2`: Adjust channel dimensions and refine skip features using attention and residual blocks.\n",
    "  - **Refinement Layer**: Enhances the reconstructed image by adding fine details using additional residual blocks.\n",
    "\n",
    "### 5. Model Initialization\n",
    "- The model is instantiated and moved to the available device (GPU if available, otherwise CPU).\n",
    "\n"
   ],
   "id": "a1d5990de207d6cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T11:59:09.802990Z",
     "start_time": "2025-01-01T11:59:09.625445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # Define the sequence of layers for the residual block\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),  # First convolutional layer\n",
    "            nn.BatchNorm2d(channels),  # Batch normalization for stabilizing training\n",
    "            nn.ReLU(inplace=True),  # ReLU activation for non-linearity\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1),  # Second convolutional layer\n",
    "            nn.BatchNorm2d(channels)  # Batch normalization after the second convolution\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add the input (residual connection) to the processed output\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        # Define the channel attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),  # Global average pooling to reduce spatial dimensions\n",
    "            nn.Conv2d(channels, channels // reduction, kernel_size=1),  # First FC layer to reduce channels\n",
    "            nn.ReLU(inplace=True),  # ReLU activation for non-linearity\n",
    "            nn.Conv2d(channels // reduction, channels, kernel_size=1),  # Second FC layer to restore channel dimensions\n",
    "            nn.Sigmoid()  # Sigmoid activation to generate attention weights\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Generate attention weights and apply them to the input\n",
    "        attention_weights = self.attention(x)\n",
    "        return x * attention_weights\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        # Define the spatial attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=kernel_size, padding=(kernel_size // 2), bias=False),  # Single convolutional layer\n",
    "            nn.Sigmoid()  # Sigmoid activation to generate spatial attention weights\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Calculate average and maximum along the channel dimension\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # Average pooling across channels\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # Max pooling across channels\n",
    "        attention_input = torch.cat([avg_out, max_out], dim=1)  # Concatenate along the channel dimension\n",
    "        attention_weights = self.attention(attention_input)  # Apply spatial attention\n",
    "        return x * attention_weights\n",
    "\n",
    "class ImageReconstructionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageReconstructionModel, self).__init__()\n",
    "\n",
    "        # Define the encoder blocks\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # Downsample input to 64 channels\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            SpatialAttention(kernel_size=7),  # Spatial attention mechanism\n",
    "            nn.Dropout(0.2)  # Dropout for regularization\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # Downsample to 128 channels\n",
    "            nn.BatchNorm2d(128),  # Batch normalization for stability\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            ChannelAttention(128),  # Channel attention mechanism\n",
    "            nn.Dropout(0.2)  # Dropout for regularization\n",
    "        )\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # Downsample to 256 channels\n",
    "            nn.BatchNorm2d(256),  # Batch normalization for stability\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            ChannelAttention(256),  # Channel attention mechanism\n",
    "            nn.Dropout(0.2)  # Dropout for regularization\n",
    "        )\n",
    "\n",
    "        # Bottleneck block with residual connections\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResidualBlock(256),  # First residual block\n",
    "            ResidualBlock(256),  # Second residual block\n",
    "            ResidualBlock(256)  # Third residual block\n",
    "        )\n",
    "\n",
    "        # Define the decoder blocks\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),  # Expand channels before upsampling\n",
    "            nn.PixelShuffle(upscale_factor=2),  # Upsampling using PixelShuffle\n",
    "            nn.BatchNorm2d(128),  # Batch normalization after upsampling\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            ResidualBlock(128),  # Residual block for feature refinement\n",
    "            SpatialAttention(kernel_size=7)  # Spatial attention mechanism\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # Expand channels before upsampling\n",
    "            nn.PixelShuffle(upscale_factor=2),  # Upsampling using PixelShuffle\n",
    "            nn.BatchNorm2d(64),  # Batch normalization after upsampling\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            ResidualBlock(64),  # Residual block for feature refinement\n",
    "            SpatialAttention(kernel_size=7)  # Spatial attention mechanism\n",
    "        )\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),  # Final upsampling preparation\n",
    "            nn.PixelShuffle(upscale_factor=2),  # Final upsampling using PixelShuffle\n",
    "            nn.Sigmoid()  # Sigmoid activation to normalize output to [0, 1]\n",
    "        )\n",
    "\n",
    "        # Skip connections\n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1),  # Adjust channels for skip connection\n",
    "            nn.BatchNorm2d(128),  # Batch normalization for stability\n",
    "            ChannelAttention(128),  # Channel attention for skip connection\n",
    "            ResidualBlock(128)  # Residual refinement for skip features\n",
    "        )\n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=1),  # Adjust channels for skip connection\n",
    "            nn.BatchNorm2d(256),  # Batch normalization for stability\n",
    "            ChannelAttention(256),  # Channel attention for skip connection\n",
    "            ResidualBlock(256)  # Residual refinement for skip features\n",
    "        )\n",
    "\n",
    "        # Refinement layer\n",
    "        self.refinement = nn.Sequential(\n",
    "            nn.Conv2d(48, 64, kernel_size=3, padding=1),  # Adjust input channels for refinement\n",
    "            nn.ReLU(inplace=True),  # ReLU activation\n",
    "            ResidualBlock(64),  # Residual block for refinement\n",
    "            ResidualBlock(64),  # Additional refinement block\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),  # Final output layer with 3 channels\n",
    "            nn.Sigmoid()  # Sigmoid activation to normalize output to [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the encoder\n",
    "        enc1 = self.encoder1(x)  # First encoding stage\n",
    "        enc2 = self.encoder2(enc1)  # Second encoding stage\n",
    "        enc3 = self.encoder3(enc2)  # Third encoding stage\n",
    "\n",
    "        # Bottleneck processing\n",
    "        bottlenecked = self.bottleneck(enc3)  # Pass through bottleneck blocks\n",
    "\n",
    "        # Skip connection from encoder2\n",
    "        aligned_enc2 = nn.functional.interpolate(enc2, size=bottlenecked.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        aligned_enc2 = self.skip2(aligned_enc2)  # Refine encoder2 features\n",
    "\n",
    "        # Decoder stage 1\n",
    "        dec1 = self.decoder1(bottlenecked + aligned_enc2)  # Combine bottleneck and refined encoder2 features\n",
    "\n",
    "        # Skip connection from encoder1\n",
    "        aligned_enc1 = nn.functional.interpolate(enc1, size=dec1.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        aligned_enc1 = self.skip1(aligned_enc1)  # Refine encoder1 features\n",
    "\n",
    "        # Decoder stage 2\n",
    "        dec2 = self.decoder2(dec1 + aligned_enc1)  # Combine decoder1 and refined encoder1 features\n",
    "\n",
    "        # Final reconstruction\n",
    "        dec3 = self.decoder3(dec2)  # Reconstruct the image\n",
    "\n",
    "        # Refinement for fine details\n",
    "        refined = self.refinement(dec3)  # Apply final refinement for output\n",
    "\n",
    "        return refined\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "model = ImageReconstructionModel().to(device)  # Move model to the chosen device\n",
    "print(model)  # Print the model architecture"
   ],
   "id": "bbbdbca6d4dce2fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageReconstructionModel(\n",
      "  (encoder1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): SpatialAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ChannelAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (encoder3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ChannelAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder1): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): SpatialAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): SpatialAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder3): Sequential(\n",
      "    (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      "  (skip1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ChannelAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (skip2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ChannelAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (refinement): Sequential(\n",
      "    (0): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "---\n",
    "## Training and Validation Loop\n",
    "\n",
    "This block trains the image reconstruction model using a combined loss function (MSE and MAE). The training includes:\n",
    "\n",
    "- **Combined Loss Function**: Balances Mean Squared Error (MSE) and Mean Absolute Error (MAE) with configurable weights.\n",
    "- **Optimizer & Scheduler**: Adam optimizer with a StepLR scheduler to adjust learning rates every 20 epochs.\n",
    "- **Training Phase**: The model is trained on masked images to minimize reconstruction loss using backpropagation.\n",
    "- **Validation Phase**: Evaluates model performance on validation data without updating weights.\n",
    "- **Logging**: Tracks and prints training and validation losses for each epoch.\n",
    "\n",
    "This setup runs for 400 epochs, leveraging a GPU (if available) for efficient training.\n"
   ],
   "id": "3bfa8a8d9e9a1d01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T17:30:29.965252Z",
     "start_time": "2025-01-01T11:59:09.838844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the combined loss function\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, mse_weight=0.5, mae_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()  # Mean Squared Error loss\n",
    "        self.mae_loss = nn.L1Loss()  # Mean Absolute Error loss\n",
    "        self.mse_weight = mse_weight  # Weight for MSE\n",
    "        self.mae_weight = mae_weight  # Weight for MAE\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        mse = self.mse_loss(outputs, target)  # Compute MSE\n",
    "        mae = self.mae_loss(outputs, target)  # Compute MAE\n",
    "        return self.mse_weight * mse + self.mae_weight * mae  # Weighted combination of both losses\n",
    "\n",
    "# Instantiate the loss function with equal weights for MSE and MAE\n",
    "loss_fn = CombinedLoss(mse_weight=0.5, mae_weight=0.5)\n",
    "\n",
    "# Adjusted Training Loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, else CPU\n",
    "model = model.to(device)  # Move the model to the appropriate device\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer with initial learning rate of 0.01\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.8)  # Reduce learning rate every 20 epochs\n",
    "\n",
    "history = {\"train_loss\": [], \"val_loss\": []}  # Dictionary to store training and validation loss history\n",
    "epochs = 400  # Total number of training epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0.0  # Initialize training loss for the epoch\n",
    "\n",
    "    # Training phase\n",
    "    for masked_image, original_image in train_loader:\n",
    "        # Move input and target to the selected device\n",
    "        masked_image, original_image = masked_image.to(device), original_image.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        # Forward pass: Generate predictions\n",
    "        outputs = model(masked_image)\n",
    "\n",
    "        # Compute the combined loss\n",
    "        loss = loss_fn(outputs, original_image)\n",
    "\n",
    "        # Backward pass: Compute gradients and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()  # Accumulate training loss for the batch\n",
    "\n",
    "    train_loss /= len(train_loader)  # Compute average training loss for the epoch\n",
    "    history[\"train_loss\"].append(train_loss)  # Save training loss\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0  # Initialize validation loss for the epoch\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for masked_image, original_image in val_loader:\n",
    "            # Move input and target to the selected device\n",
    "            masked_image, original_image = masked_image.to(device), original_image.to(device)\n",
    "            outputs = model(masked_image)  # Forward pass\n",
    "            loss = loss_fn(outputs, original_image)  # Compute validation loss\n",
    "            val_loss += loss.item()  # Accumulate validation loss for the batch\n",
    "\n",
    "    val_loss /= len(val_loader)  # Compute average validation loss for the epoch\n",
    "    history[\"val_loss\"].append(val_loss)  # Save validation loss\n",
    "\n",
    "    # Print loss values for the current epoch\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    scheduler.step()  # Update learning rate based on the scheduler"
   ],
   "id": "a91ed4239114068f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Train Loss: 0.0743, Val Loss: 0.0528\n",
      "Epoch 2/400, Train Loss: 0.0393, Val Loss: 0.0319\n",
      "Epoch 3/400, Train Loss: 0.0333, Val Loss: 0.0413\n",
      "Epoch 4/400, Train Loss: 0.0306, Val Loss: 0.0664\n",
      "Epoch 5/400, Train Loss: 0.0291, Val Loss: 0.0290\n",
      "Epoch 6/400, Train Loss: 0.0259, Val Loss: 0.0276\n",
      "Epoch 7/400, Train Loss: 0.0251, Val Loss: 0.0223\n",
      "Epoch 8/400, Train Loss: 0.0241, Val Loss: 0.0218\n",
      "Epoch 9/400, Train Loss: 0.0239, Val Loss: 0.0319\n",
      "Epoch 10/400, Train Loss: 0.0236, Val Loss: 0.0252\n",
      "Epoch 11/400, Train Loss: 0.0225, Val Loss: 0.0261\n",
      "Epoch 12/400, Train Loss: 0.0227, Val Loss: 0.0248\n",
      "Epoch 13/400, Train Loss: 0.0220, Val Loss: 0.0220\n",
      "Epoch 14/400, Train Loss: 0.0221, Val Loss: 0.0197\n",
      "Epoch 15/400, Train Loss: 0.0213, Val Loss: 0.0200\n",
      "Epoch 16/400, Train Loss: 0.0215, Val Loss: 0.0191\n",
      "Epoch 17/400, Train Loss: 0.0213, Val Loss: 0.0208\n",
      "Epoch 18/400, Train Loss: 0.0207, Val Loss: 0.0251\n",
      "Epoch 19/400, Train Loss: 0.0205, Val Loss: 0.0181\n",
      "Epoch 20/400, Train Loss: 0.0202, Val Loss: 0.0398\n",
      "Epoch 21/400, Train Loss: 0.0198, Val Loss: 0.0178\n",
      "Epoch 22/400, Train Loss: 0.0196, Val Loss: 0.0195\n",
      "Epoch 23/400, Train Loss: 0.0192, Val Loss: 0.0201\n",
      "Epoch 24/400, Train Loss: 0.0190, Val Loss: 0.0169\n",
      "Epoch 25/400, Train Loss: 0.0189, Val Loss: 0.0173\n",
      "Epoch 26/400, Train Loss: 0.0189, Val Loss: 0.0167\n",
      "Epoch 27/400, Train Loss: 0.0186, Val Loss: 0.0171\n",
      "Epoch 28/400, Train Loss: 0.0191, Val Loss: 0.0170\n",
      "Epoch 29/400, Train Loss: 0.0182, Val Loss: 0.0197\n",
      "Epoch 30/400, Train Loss: 0.0182, Val Loss: 0.0170\n",
      "Epoch 31/400, Train Loss: 0.0182, Val Loss: 0.0175\n",
      "Epoch 32/400, Train Loss: 0.0181, Val Loss: 0.0171\n",
      "Epoch 33/400, Train Loss: 0.0179, Val Loss: 0.0192\n",
      "Epoch 34/400, Train Loss: 0.0178, Val Loss: 0.0290\n",
      "Epoch 35/400, Train Loss: 0.0179, Val Loss: 0.0207\n",
      "Epoch 36/400, Train Loss: 0.0174, Val Loss: 0.0221\n",
      "Epoch 37/400, Train Loss: 0.0174, Val Loss: 0.0209\n",
      "Epoch 38/400, Train Loss: 0.0172, Val Loss: 0.0179\n",
      "Epoch 39/400, Train Loss: 0.0173, Val Loss: 0.0144\n",
      "Epoch 40/400, Train Loss: 0.0170, Val Loss: 0.0188\n",
      "Epoch 41/400, Train Loss: 0.0166, Val Loss: 0.0154\n",
      "Epoch 42/400, Train Loss: 0.0164, Val Loss: 0.0155\n",
      "Epoch 43/400, Train Loss: 0.0162, Val Loss: 0.0141\n",
      "Epoch 44/400, Train Loss: 0.0162, Val Loss: 0.0145\n",
      "Epoch 45/400, Train Loss: 0.0161, Val Loss: 0.0144\n",
      "Epoch 46/400, Train Loss: 0.0161, Val Loss: 0.0144\n",
      "Epoch 47/400, Train Loss: 0.0159, Val Loss: 0.0137\n",
      "Epoch 48/400, Train Loss: 0.0159, Val Loss: 0.0139\n",
      "Epoch 49/400, Train Loss: 0.0158, Val Loss: 0.0142\n",
      "Epoch 50/400, Train Loss: 0.0156, Val Loss: 0.0131\n",
      "Epoch 51/400, Train Loss: 0.0157, Val Loss: 0.0148\n",
      "Epoch 52/400, Train Loss: 0.0157, Val Loss: 0.0200\n",
      "Epoch 53/400, Train Loss: 0.0154, Val Loss: 0.0132\n",
      "Epoch 54/400, Train Loss: 0.0153, Val Loss: 0.0142\n",
      "Epoch 55/400, Train Loss: 0.0154, Val Loss: 0.0156\n",
      "Epoch 56/400, Train Loss: 0.0153, Val Loss: 0.0130\n",
      "Epoch 57/400, Train Loss: 0.0151, Val Loss: 0.0128\n",
      "Epoch 58/400, Train Loss: 0.0151, Val Loss: 0.0123\n",
      "Epoch 59/400, Train Loss: 0.0150, Val Loss: 0.0135\n",
      "Epoch 60/400, Train Loss: 0.0150, Val Loss: 0.0176\n",
      "Epoch 61/400, Train Loss: 0.0147, Val Loss: 0.0133\n",
      "Epoch 62/400, Train Loss: 0.0145, Val Loss: 0.0169\n",
      "Epoch 63/400, Train Loss: 0.0146, Val Loss: 0.0130\n",
      "Epoch 64/400, Train Loss: 0.0146, Val Loss: 0.0154\n",
      "Epoch 65/400, Train Loss: 0.0146, Val Loss: 0.0143\n",
      "Epoch 66/400, Train Loss: 0.0144, Val Loss: 0.0122\n",
      "Epoch 67/400, Train Loss: 0.0145, Val Loss: 0.0129\n",
      "Epoch 68/400, Train Loss: 0.0143, Val Loss: 0.0144\n",
      "Epoch 69/400, Train Loss: 0.0144, Val Loss: 0.0180\n",
      "Epoch 70/400, Train Loss: 0.0144, Val Loss: 0.0155\n",
      "Epoch 71/400, Train Loss: 0.0143, Val Loss: 0.0153\n",
      "Epoch 72/400, Train Loss: 0.0142, Val Loss: 0.0138\n",
      "Epoch 73/400, Train Loss: 0.0143, Val Loss: 0.0161\n",
      "Epoch 74/400, Train Loss: 0.0142, Val Loss: 0.0135\n",
      "Epoch 75/400, Train Loss: 0.0142, Val Loss: 0.0123\n",
      "Epoch 76/400, Train Loss: 0.0141, Val Loss: 0.0132\n",
      "Epoch 77/400, Train Loss: 0.0142, Val Loss: 0.0127\n",
      "Epoch 78/400, Train Loss: 0.0140, Val Loss: 0.0126\n",
      "Epoch 79/400, Train Loss: 0.0142, Val Loss: 0.0137\n",
      "Epoch 80/400, Train Loss: 0.0140, Val Loss: 0.0146\n",
      "Epoch 81/400, Train Loss: 0.0138, Val Loss: 0.0136\n",
      "Epoch 82/400, Train Loss: 0.0137, Val Loss: 0.0113\n",
      "Epoch 83/400, Train Loss: 0.0138, Val Loss: 0.0130\n",
      "Epoch 84/400, Train Loss: 0.0137, Val Loss: 0.0135\n",
      "Epoch 85/400, Train Loss: 0.0136, Val Loss: 0.0153\n",
      "Epoch 86/400, Train Loss: 0.0137, Val Loss: 0.0119\n",
      "Epoch 87/400, Train Loss: 0.0136, Val Loss: 0.0207\n",
      "Epoch 88/400, Train Loss: 0.0137, Val Loss: 0.0147\n",
      "Epoch 89/400, Train Loss: 0.0136, Val Loss: 0.0114\n",
      "Epoch 90/400, Train Loss: 0.0136, Val Loss: 0.0119\n",
      "Epoch 91/400, Train Loss: 0.0136, Val Loss: 0.0116\n",
      "Epoch 92/400, Train Loss: 0.0136, Val Loss: 0.0114\n",
      "Epoch 93/400, Train Loss: 0.0135, Val Loss: 0.0132\n",
      "Epoch 94/400, Train Loss: 0.0135, Val Loss: 0.0117\n",
      "Epoch 95/400, Train Loss: 0.0135, Val Loss: 0.0145\n",
      "Epoch 96/400, Train Loss: 0.0135, Val Loss: 0.0116\n",
      "Epoch 97/400, Train Loss: 0.0134, Val Loss: 0.0137\n",
      "Epoch 98/400, Train Loss: 0.0134, Val Loss: 0.0123\n",
      "Epoch 99/400, Train Loss: 0.0133, Val Loss: 0.0118\n",
      "Epoch 100/400, Train Loss: 0.0133, Val Loss: 0.0130\n",
      "Epoch 101/400, Train Loss: 0.0132, Val Loss: 0.0121\n",
      "Epoch 102/400, Train Loss: 0.0131, Val Loss: 0.0144\n",
      "Epoch 103/400, Train Loss: 0.0130, Val Loss: 0.0118\n",
      "Epoch 104/400, Train Loss: 0.0130, Val Loss: 0.0113\n",
      "Epoch 105/400, Train Loss: 0.0131, Val Loss: 0.0115\n",
      "Epoch 106/400, Train Loss: 0.0130, Val Loss: 0.0119\n",
      "Epoch 107/400, Train Loss: 0.0130, Val Loss: 0.0127\n",
      "Epoch 108/400, Train Loss: 0.0129, Val Loss: 0.0119\n",
      "Epoch 109/400, Train Loss: 0.0130, Val Loss: 0.0153\n",
      "Epoch 110/400, Train Loss: 0.0129, Val Loss: 0.0130\n",
      "Epoch 111/400, Train Loss: 0.0129, Val Loss: 0.0120\n",
      "Epoch 112/400, Train Loss: 0.0129, Val Loss: 0.0130\n",
      "Epoch 113/400, Train Loss: 0.0129, Val Loss: 0.0135\n",
      "Epoch 114/400, Train Loss: 0.0128, Val Loss: 0.0122\n",
      "Epoch 115/400, Train Loss: 0.0128, Val Loss: 0.0124\n",
      "Epoch 116/400, Train Loss: 0.0128, Val Loss: 0.0131\n",
      "Epoch 117/400, Train Loss: 0.0129, Val Loss: 0.0126\n",
      "Epoch 118/400, Train Loss: 0.0127, Val Loss: 0.0153\n",
      "Epoch 119/400, Train Loss: 0.0127, Val Loss: 0.0145\n",
      "Epoch 120/400, Train Loss: 0.0129, Val Loss: 0.0119\n",
      "Epoch 121/400, Train Loss: 0.0125, Val Loss: 0.0145\n",
      "Epoch 122/400, Train Loss: 0.0126, Val Loss: 0.0156\n",
      "Epoch 123/400, Train Loss: 0.0126, Val Loss: 0.0111\n",
      "Epoch 124/400, Train Loss: 0.0126, Val Loss: 0.0169\n",
      "Epoch 125/400, Train Loss: 0.0125, Val Loss: 0.0120\n",
      "Epoch 126/400, Train Loss: 0.0126, Val Loss: 0.0164\n",
      "Epoch 127/400, Train Loss: 0.0125, Val Loss: 0.0145\n",
      "Epoch 128/400, Train Loss: 0.0125, Val Loss: 0.0153\n",
      "Epoch 129/400, Train Loss: 0.0125, Val Loss: 0.0118\n",
      "Epoch 130/400, Train Loss: 0.0124, Val Loss: 0.0113\n",
      "Epoch 131/400, Train Loss: 0.0125, Val Loss: 0.0112\n",
      "Epoch 132/400, Train Loss: 0.0125, Val Loss: 0.0128\n",
      "Epoch 133/400, Train Loss: 0.0124, Val Loss: 0.0110\n",
      "Epoch 134/400, Train Loss: 0.0124, Val Loss: 0.0118\n",
      "Epoch 135/400, Train Loss: 0.0125, Val Loss: 0.0119\n",
      "Epoch 136/400, Train Loss: 0.0124, Val Loss: 0.0139\n",
      "Epoch 137/400, Train Loss: 0.0124, Val Loss: 0.0133\n",
      "Epoch 138/400, Train Loss: 0.0124, Val Loss: 0.0106\n",
      "Epoch 139/400, Train Loss: 0.0124, Val Loss: 0.0120\n",
      "Epoch 140/400, Train Loss: 0.0123, Val Loss: 0.0134\n",
      "Epoch 141/400, Train Loss: 0.0122, Val Loss: 0.0122\n",
      "Epoch 142/400, Train Loss: 0.0122, Val Loss: 0.0118\n",
      "Epoch 143/400, Train Loss: 0.0122, Val Loss: 0.0117\n",
      "Epoch 144/400, Train Loss: 0.0122, Val Loss: 0.0138\n",
      "Epoch 145/400, Train Loss: 0.0122, Val Loss: 0.0126\n",
      "Epoch 146/400, Train Loss: 0.0122, Val Loss: 0.0119\n",
      "Epoch 147/400, Train Loss: 0.0122, Val Loss: 0.0133\n",
      "Epoch 148/400, Train Loss: 0.0121, Val Loss: 0.0122\n",
      "Epoch 149/400, Train Loss: 0.0123, Val Loss: 0.0112\n",
      "Epoch 150/400, Train Loss: 0.0121, Val Loss: 0.0121\n",
      "Epoch 151/400, Train Loss: 0.0121, Val Loss: 0.0121\n",
      "Epoch 152/400, Train Loss: 0.0122, Val Loss: 0.0131\n",
      "Epoch 153/400, Train Loss: 0.0121, Val Loss: 0.0136\n",
      "Epoch 154/400, Train Loss: 0.0121, Val Loss: 0.0120\n",
      "Epoch 155/400, Train Loss: 0.0121, Val Loss: 0.0127\n",
      "Epoch 156/400, Train Loss: 0.0121, Val Loss: 0.0135\n",
      "Epoch 157/400, Train Loss: 0.0121, Val Loss: 0.0134\n",
      "Epoch 158/400, Train Loss: 0.0121, Val Loss: 0.0114\n",
      "Epoch 159/400, Train Loss: 0.0120, Val Loss: 0.0140\n",
      "Epoch 160/400, Train Loss: 0.0120, Val Loss: 0.0115\n",
      "Epoch 161/400, Train Loss: 0.0120, Val Loss: 0.0116\n",
      "Epoch 162/400, Train Loss: 0.0119, Val Loss: 0.0113\n",
      "Epoch 163/400, Train Loss: 0.0120, Val Loss: 0.0113\n",
      "Epoch 164/400, Train Loss: 0.0121, Val Loss: 0.0121\n",
      "Epoch 165/400, Train Loss: 0.0119, Val Loss: 0.0125\n",
      "Epoch 166/400, Train Loss: 0.0119, Val Loss: 0.0148\n",
      "Epoch 167/400, Train Loss: 0.0119, Val Loss: 0.0114\n",
      "Epoch 168/400, Train Loss: 0.0119, Val Loss: 0.0130\n",
      "Epoch 169/400, Train Loss: 0.0119, Val Loss: 0.0130\n",
      "Epoch 170/400, Train Loss: 0.0119, Val Loss: 0.0129\n",
      "Epoch 171/400, Train Loss: 0.0119, Val Loss: 0.0130\n",
      "Epoch 172/400, Train Loss: 0.0119, Val Loss: 0.0126\n",
      "Epoch 173/400, Train Loss: 0.0119, Val Loss: 0.0113\n",
      "Epoch 174/400, Train Loss: 0.0119, Val Loss: 0.0111\n",
      "Epoch 175/400, Train Loss: 0.0118, Val Loss: 0.0125\n",
      "Epoch 176/400, Train Loss: 0.0118, Val Loss: 0.0122\n",
      "Epoch 177/400, Train Loss: 0.0119, Val Loss: 0.0110\n",
      "Epoch 178/400, Train Loss: 0.0118, Val Loss: 0.0113\n",
      "Epoch 179/400, Train Loss: 0.0118, Val Loss: 0.0125\n",
      "Epoch 180/400, Train Loss: 0.0118, Val Loss: 0.0106\n",
      "Epoch 181/400, Train Loss: 0.0117, Val Loss: 0.0115\n",
      "Epoch 182/400, Train Loss: 0.0118, Val Loss: 0.0116\n",
      "Epoch 183/400, Train Loss: 0.0118, Val Loss: 0.0102\n",
      "Epoch 184/400, Train Loss: 0.0118, Val Loss: 0.0111\n",
      "Epoch 185/400, Train Loss: 0.0117, Val Loss: 0.0122\n",
      "Epoch 186/400, Train Loss: 0.0117, Val Loss: 0.0130\n",
      "Epoch 187/400, Train Loss: 0.0117, Val Loss: 0.0110\n",
      "Epoch 188/400, Train Loss: 0.0117, Val Loss: 0.0143\n",
      "Epoch 189/400, Train Loss: 0.0117, Val Loss: 0.0124\n",
      "Epoch 190/400, Train Loss: 0.0117, Val Loss: 0.0113\n",
      "Epoch 191/400, Train Loss: 0.0117, Val Loss: 0.0121\n",
      "Epoch 192/400, Train Loss: 0.0117, Val Loss: 0.0132\n",
      "Epoch 193/400, Train Loss: 0.0117, Val Loss: 0.0114\n",
      "Epoch 194/400, Train Loss: 0.0117, Val Loss: 0.0115\n",
      "Epoch 195/400, Train Loss: 0.0117, Val Loss: 0.0124\n",
      "Epoch 196/400, Train Loss: 0.0117, Val Loss: 0.0114\n",
      "Epoch 197/400, Train Loss: 0.0117, Val Loss: 0.0124\n",
      "Epoch 198/400, Train Loss: 0.0117, Val Loss: 0.0133\n",
      "Epoch 199/400, Train Loss: 0.0117, Val Loss: 0.0114\n",
      "Epoch 200/400, Train Loss: 0.0117, Val Loss: 0.0130\n",
      "Epoch 201/400, Train Loss: 0.0116, Val Loss: 0.0119\n",
      "Epoch 202/400, Train Loss: 0.0116, Val Loss: 0.0122\n",
      "Epoch 203/400, Train Loss: 0.0116, Val Loss: 0.0123\n",
      "Epoch 204/400, Train Loss: 0.0116, Val Loss: 0.0116\n",
      "Epoch 205/400, Train Loss: 0.0116, Val Loss: 0.0108\n",
      "Epoch 206/400, Train Loss: 0.0115, Val Loss: 0.0114\n",
      "Epoch 207/400, Train Loss: 0.0116, Val Loss: 0.0112\n",
      "Epoch 208/400, Train Loss: 0.0116, Val Loss: 0.0116\n",
      "Epoch 209/400, Train Loss: 0.0116, Val Loss: 0.0109\n",
      "Epoch 210/400, Train Loss: 0.0116, Val Loss: 0.0114\n",
      "Epoch 211/400, Train Loss: 0.0115, Val Loss: 0.0116\n",
      "Epoch 212/400, Train Loss: 0.0116, Val Loss: 0.0121\n",
      "Epoch 213/400, Train Loss: 0.0115, Val Loss: 0.0116\n",
      "Epoch 214/400, Train Loss: 0.0115, Val Loss: 0.0111\n",
      "Epoch 215/400, Train Loss: 0.0115, Val Loss: 0.0115\n",
      "Epoch 216/400, Train Loss: 0.0115, Val Loss: 0.0137\n",
      "Epoch 217/400, Train Loss: 0.0115, Val Loss: 0.0119\n",
      "Epoch 218/400, Train Loss: 0.0115, Val Loss: 0.0120\n",
      "Epoch 219/400, Train Loss: 0.0115, Val Loss: 0.0124\n",
      "Epoch 220/400, Train Loss: 0.0115, Val Loss: 0.0113\n",
      "Epoch 221/400, Train Loss: 0.0115, Val Loss: 0.0114\n",
      "Epoch 222/400, Train Loss: 0.0115, Val Loss: 0.0125\n",
      "Epoch 223/400, Train Loss: 0.0114, Val Loss: 0.0121\n",
      "Epoch 224/400, Train Loss: 0.0114, Val Loss: 0.0117\n",
      "Epoch 225/400, Train Loss: 0.0114, Val Loss: 0.0121\n",
      "Epoch 226/400, Train Loss: 0.0114, Val Loss: 0.0112\n",
      "Epoch 227/400, Train Loss: 0.0114, Val Loss: 0.0128\n",
      "Epoch 228/400, Train Loss: 0.0114, Val Loss: 0.0113\n",
      "Epoch 229/400, Train Loss: 0.0114, Val Loss: 0.0111\n",
      "Epoch 230/400, Train Loss: 0.0114, Val Loss: 0.0112\n",
      "Epoch 231/400, Train Loss: 0.0114, Val Loss: 0.0120\n",
      "Epoch 232/400, Train Loss: 0.0114, Val Loss: 0.0122\n",
      "Epoch 233/400, Train Loss: 0.0114, Val Loss: 0.0108\n",
      "Epoch 234/400, Train Loss: 0.0114, Val Loss: 0.0115\n",
      "Epoch 235/400, Train Loss: 0.0114, Val Loss: 0.0124\n",
      "Epoch 236/400, Train Loss: 0.0114, Val Loss: 0.0117\n",
      "Epoch 237/400, Train Loss: 0.0114, Val Loss: 0.0118\n",
      "Epoch 238/400, Train Loss: 0.0114, Val Loss: 0.0104\n",
      "Epoch 239/400, Train Loss: 0.0114, Val Loss: 0.0126\n",
      "Epoch 240/400, Train Loss: 0.0114, Val Loss: 0.0123\n",
      "Epoch 241/400, Train Loss: 0.0114, Val Loss: 0.0111\n",
      "Epoch 242/400, Train Loss: 0.0113, Val Loss: 0.0119\n",
      "Epoch 243/400, Train Loss: 0.0113, Val Loss: 0.0139\n",
      "Epoch 244/400, Train Loss: 0.0113, Val Loss: 0.0115\n",
      "Epoch 245/400, Train Loss: 0.0113, Val Loss: 0.0113\n",
      "Epoch 246/400, Train Loss: 0.0113, Val Loss: 0.0110\n",
      "Epoch 247/400, Train Loss: 0.0113, Val Loss: 0.0118\n",
      "Epoch 248/400, Train Loss: 0.0113, Val Loss: 0.0119\n",
      "Epoch 249/400, Train Loss: 0.0113, Val Loss: 0.0114\n",
      "Epoch 250/400, Train Loss: 0.0113, Val Loss: 0.0112\n",
      "Epoch 251/400, Train Loss: 0.0113, Val Loss: 0.0121\n",
      "Epoch 252/400, Train Loss: 0.0113, Val Loss: 0.0113\n",
      "Epoch 253/400, Train Loss: 0.0113, Val Loss: 0.0113\n",
      "Epoch 254/400, Train Loss: 0.0113, Val Loss: 0.0120\n",
      "Epoch 255/400, Train Loss: 0.0113, Val Loss: 0.0118\n",
      "Epoch 256/400, Train Loss: 0.0113, Val Loss: 0.0123\n",
      "Epoch 257/400, Train Loss: 0.0113, Val Loss: 0.0112\n",
      "Epoch 258/400, Train Loss: 0.0113, Val Loss: 0.0119\n",
      "Epoch 259/400, Train Loss: 0.0113, Val Loss: 0.0118\n",
      "Epoch 260/400, Train Loss: 0.0113, Val Loss: 0.0118\n",
      "Epoch 261/400, Train Loss: 0.0113, Val Loss: 0.0115\n",
      "Epoch 262/400, Train Loss: 0.0113, Val Loss: 0.0123\n",
      "Epoch 263/400, Train Loss: 0.0113, Val Loss: 0.0112\n",
      "Epoch 264/400, Train Loss: 0.0112, Val Loss: 0.0107\n",
      "Epoch 265/400, Train Loss: 0.0112, Val Loss: 0.0112\n",
      "Epoch 266/400, Train Loss: 0.0113, Val Loss: 0.0106\n",
      "Epoch 267/400, Train Loss: 0.0113, Val Loss: 0.0118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 38\u001B[0m\n\u001B[0;32m     36\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# Forward pass: Get outputs\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmasked_image\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Ensure your model returns a single output\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Compute combined loss\u001B[39;00m\n\u001B[0;32m     41\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, original_image)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[3], line 144\u001B[0m, in \u001B[0;36mImageReconstructionModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    141\u001B[0m aligned_enc1 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39minterpolate(enc1, size\u001B[38;5;241m=\u001B[39mdec1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m:], mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, align_corners\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    142\u001B[0m aligned_enc1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip1(aligned_enc1)  \u001B[38;5;66;03m# Match channels to dec1 (128)\u001B[39;00m\n\u001B[1;32m--> 144\u001B[0m dec2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdec1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43maligned_enc1\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Combine decoder1 with encoder1 features\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;66;03m# Final reconstruction\u001B[39;00m\n\u001B[0;32m    147\u001B[0m dec3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder3(dec2)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:175\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    168\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    170\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 175\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[0;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\sapir\\Lib\\site-packages\\torch\\nn\\functional.py:2509\u001B[0m, in \u001B[0;36mbatch_norm\u001B[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[0;32m   2506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[0;32m   2507\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[1;32m-> 2509\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2510\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\n\u001B[0;32m   2511\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Plotting Training and Validation Losses\n",
    "\n",
    "This block visualizes the training and validation loss trends over epochs to assess the model's performance during training. The plot includes:\n",
    "\n",
    "- **Training Loss**: Monitors how well the model learns during training.\n",
    "- **Validation Loss**: Tracks the model's performance on unseen data.\n",
    "\n",
    "The graph helps identify overfitting, underfitting, or convergence issues.\n"
   ],
   "id": "f20284a207ba3e40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T17:30:29.970241800Z",
     "start_time": "2025-01-01T10:03:51.402450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_losses(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(history[\"train_loss\"], label=\"Training Loss\")\n",
    "    \n",
    "    # Plot validation loss\n",
    "    plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    \n",
    "    # Add labels, title, and legend\n",
    "    plt.title(\"Training and Validation Losses\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_losses(history)\n"
   ],
   "id": "21fbe2c28b6bafcd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test Set Evaluation\n",
    "\n",
    "This block evaluates the model's performance on the test set by:\n",
    "\n",
    "- Replacing reconstructed image pixels based on a \"blackness\" threshold.\n",
    "- Calculating Mean Squared Error (MSE) and Mean Absolute Error (MAE) for each image pair.\n",
    "- Printing the average MSE and MAE as final results.\n"
   ],
   "id": "95e479c2a2b0c2e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T17:30:29.976225600Z",
     "start_time": "2025-01-01T10:03:59.282423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function to replace colorful pixels in the reconstructed image\n",
    "def replace_colorful_pixels(masked_image, reconstructed_image, threshold=0.2):\n",
    "   \n",
    "    # Convert the masked image to grayscale to evaluate blackness\n",
    "    grayscale_mask = np.mean(masked_image, axis=0)  # Average across color channels\n",
    "    replace_condition = grayscale_mask > threshold  # Pixels that are not black enough\n",
    "\n",
    "    # Replace pixels in the reconstructed image where the condition is met\n",
    "    reconstructed_image[:, replace_condition] = masked_image[:, replace_condition]\n",
    "\n",
    "    return reconstructed_image\n",
    "\n",
    "# Lists to store MSE and MAE for each image\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "\n",
    "# Evaluate on the test set\n",
    "print(\"Evaluating the Attention Model on the test set...\")\n",
    "with torch.no_grad():\n",
    "    for masked_images, original_images in test_loader:\n",
    "        masked_images = masked_images.to(device)\n",
    "        original_images = original_images.to(device)\n",
    "\n",
    "        # Generate reconstructed images using the attention-based model\n",
    "        reconstructed_images = model(masked_images)\n",
    "\n",
    "        # Convert to NumPy arrays\n",
    "        reconstructed_images = reconstructed_images.cpu().numpy()\n",
    "        original_images = original_images.cpu().numpy()\n",
    "        masked_images = masked_images.cpu().numpy()\n",
    "\n",
    "        # Apply the helper function to replace colorful pixels\n",
    "        for i in range(reconstructed_images.shape[0]):\n",
    "            reconstructed_images[i] = replace_colorful_pixels(\n",
    "                masked_images[i], reconstructed_images[i], threshold=0.1\n",
    "            )\n",
    "\n",
    "        # Scale to [0, 255] for evaluation\n",
    "        reconstructed_images = np.clip(reconstructed_images * 255, 0, 255)\n",
    "        original_images = np.clip(original_images * 255, 0, 255)\n",
    "\n",
    "        # Compute MSE and MAE for each image pair\n",
    "        for reconstructed, original in zip(reconstructed_images, original_images):\n",
    "            mse = np.mean((original - reconstructed) ** 2)  # Per-image MSE\n",
    "            mae = np.mean(np.abs(original - reconstructed))  # Per-image MAE\n",
    "            mse_list.append(mse)\n",
    "            mae_list.append(mae)\n",
    "\n",
    "# Calculate average MSE and MAE across all images\n",
    "average_mse = np.mean(mse_list)\n",
    "average_mae = np.mean(mae_list)\n",
    "\n",
    "# Print final results\n",
    "print(f\"Test Results - Average MSE: {average_mse:.4f}\")\n",
    "print(f\"Test Results - Average MAE: {average_mae:.4f}\")"
   ],
   "id": "68da2a7faa713284",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the Attention Model on the test set...\n",
      "Test Results - Average MSE: 177.6620\n",
      "Test Results - Average MAE: 2.5016\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "---\n",
    "## Visualizing Test Set Images and Reconstructions\n",
    "\n",
    "This block visualizes a grid of masked test set images alongside their reconstructed versions generated by the model. Key details:\n",
    "\n",
    "- **Input**: Masked images from the test set.\n",
    "- **Output**: Corresponding reconstructed images.\n",
    "- **Visualization**: Arranged in a 4-row grid:\n",
    "  - Rows 1 and 3: Masked test set images.\n",
    "  - Rows 2 and 4: Reconstructed test set images.\n"
   ],
   "id": "3fe6130004ba7f9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T17:30:34.013372Z",
     "start_time": "2025-01-01T17:30:34.004876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_reference_images(model, reference_images_dir, transform, grid_size=5):\n",
    "\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "    # Load masked images\n",
    "    masked_image_files = sorted(os.listdir(reference_images_dir))\n",
    "    masked_images = []\n",
    "    for file_name in masked_image_files[:2 * grid_size]:  # Limit to the first 2 * grid_size images\n",
    "        image_path = os.path.join(reference_images_dir, file_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Open image in RGB format\n",
    "        masked_images.append(transform(image))  # Apply transformations (e.g., ToTensor)\n",
    "\n",
    "    # Stack into a batch and move to the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    masked_images = torch.stack(masked_images).to(device)  # Shape: [batch_size, channels, height, width]\n",
    "\n",
    "    # Generate reconstructed images\n",
    "    with torch.no_grad():\n",
    "        reconstructed_images = model(masked_images)  # Model output\n",
    "        reconstructed_images = reconstructed_images.cpu()  # Move to CPU for visualization\n",
    "\n",
    "    # Convert tensors to numpy arrays for processing\n",
    "    masked_images_np = masked_images.permute(0, 2, 3, 1).cpu().numpy()  # [batch, H, W, C]\n",
    "    reconstructed_images_np = reconstructed_images.permute(0, 2, 3, 1).numpy()  # [batch, H, W, C]\n",
    "\n",
    "    # Normalize both masked and reconstructed images to [0, 1] range\n",
    "    masked_images_np = np.clip(masked_images_np, 0, 1)\n",
    "    reconstructed_images_np = np.clip(reconstructed_images_np, 0, 1)\n",
    "\n",
    "    # Scale both masked and reconstructed images to [0, 255] for visualization\n",
    "    masked_images_np = (masked_images_np * 255).astype(np.uint8)\n",
    "    reconstructed_images_np = (reconstructed_images_np * 255).astype(np.uint8)\n",
    "\n",
    "    # Visualization with a 4-row grid\n",
    "    fig, axs = plt.subplots(4, grid_size, figsize=(15, 12))  # 4 rows, grid_size columns\n",
    "\n",
    "    # First set of images (rows 1 and 2)\n",
    "    for i in range(grid_size):\n",
    "        # Row 1: Masked images\n",
    "        axs[0, i].imshow(masked_images_np[i])\n",
    "        axs[0, i].axis(\"off\")\n",
    "        axs[0, i].set_title(f\"Masked {i+1}\", fontsize=16)\n",
    "\n",
    "        # Row 2: Reconstructed images\n",
    "        axs[1, i].imshow(reconstructed_images_np[i])\n",
    "        axs[1, i].axis(\"off\")\n",
    "        axs[1, i].set_title(f\"Reconstructed {i+1}\", fontsize=16)\n",
    "\n",
    "    # Second set of images (rows 3 and 4)\n",
    "    for i in range(grid_size, 2 * grid_size):\n",
    "        # Row 3: Masked images\n",
    "        axs[2, i - grid_size].imshow(masked_images_np[i])\n",
    "        axs[2, i - grid_size].axis(\"off\")\n",
    "        axs[2, i - grid_size].set_title(f\"Masked {i+1}\", fontsize=16)\n",
    "\n",
    "        # Row 4: Reconstructed images\n",
    "        axs[3, i - grid_size].imshow(reconstructed_images_np[i])\n",
    "        axs[3, i - grid_size].axis(\"off\")\n",
    "        axs[3, i - grid_size].set_title(f\"Reconstructed {i+1}\", fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Path to reference images\n",
    "reference_images_dir = os.path.join(\"..\", \"Reference_Images\")\n",
    "\n",
    "# Visualize a few images of the train set\n",
    "visualize_reference_images(model, reference_images_dir, transform)"
   ],
   "id": "bee3002fc056c987",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Saving the Model\n",
    "\n",
    "This block saves the entire attention model, including its architecture and weights, to a specified directory for future use.\n"
   ],
   "id": "fb040461b2348a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T18:09:13.848917Z",
     "start_time": "2025-01-01T18:09:13.622704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Assume ImageReconstructionModel is already defined earlier in this training file\n",
    "\n",
    "# Parent directory for saving models\n",
    "parent_dir = os.path.join(\"..\", \"saved_models\", \"AttentionModel\")\n",
    "\n",
    "# Create the parent directory if it doesn't exist\n",
    "os.makedirs(parent_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths for saving the model\n",
    "entire_model_path = os.path.join(parent_dir, \"attention_model.pth\")\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageReconstructionModel().to(device)\n",
    "\n",
    "# Save the entire model (architecture + weights)\n",
    "torch.save(model, entire_model_path)\n",
    "print(f\"Entire model saved to: {entire_model_path}\")\n",
    "\n"
   ],
   "id": "dc21597ade2b678f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire model saved to: ..\\saved_models\\AttentionModel\\attention_model.pth\n",
      "ImageReconstructionModel(\n",
      "  (encoder1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): SpatialAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ChannelAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (encoder3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ChannelAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder1): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): SpatialAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): SpatialAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder3): Sequential(\n",
      "    (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      "  (skip1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ChannelAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (skip2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ChannelAttention(\n",
      "      (attention): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (refinement): Sequential(\n",
      "    (0): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
