{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Image Reconstruction: Linear Regression\n",
    "\n",
    "Identifies masked regions in images, divides them into subregions, predicts pixel values, and evaluates reconstruction results."
   ],
   "id": "d77648d6d975f45f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.315834Z",
     "start_time": "2025-01-05T10:52:02.311780Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from find_black_rectangle import find_black_rectangle"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Split Region\n",
    "\n",
    "Divides the identified black region into smaller subregions for localized processing."
   ],
   "id": "6e3ee62ee36ed04b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.396681Z",
     "start_time": "2025-01-05T10:52:02.391633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_region(x_start, y_start, x_end, y_end, num_splits=4):\n",
    "    \"\"\"\n",
    "    Divides the black region into smaller subregions.\n",
    "    Returns a list of bounding boxes for each subregion.\n",
    "    \"\"\"\n",
    "    subregions = []\n",
    "    height = y_end - y_start\n",
    "    width = x_end - x_start\n",
    "\n",
    "    num_rows = int(np.sqrt(num_splits))  # Number of rows/columns to divide into\n",
    "    step_y = height // num_rows\n",
    "    step_x = width // num_rows\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_rows):\n",
    "            sub_x_start = x_start + j * step_x\n",
    "            sub_y_start = y_start + i * step_y\n",
    "            sub_x_end = sub_x_start + step_x\n",
    "            sub_y_end = sub_y_start + step_y\n",
    "            subregions.append((sub_x_start, sub_y_start, sub_x_end, sub_y_end))\n",
    "\n",
    "    return subregions"
   ],
   "id": "cb05f5816b096104",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Merge Training and Validation Datasets\n",
    "\n",
    "Merges the training and validation datasets into a single directory for training."
   ],
   "id": "ede1fa8e4b022444"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.424301Z",
     "start_time": "2025-01-05T10:52:02.419576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Final\n",
    "def merge_datasets(train_dir, validation_dir):\n",
    "    \"\"\"\n",
    "    Reads images from both the training and validation directories.\n",
    "    Combines their data into a single set for processing without modifying the files.\n",
    "    \"\"\"\n",
    "    combined_files = []\n",
    "\n",
    "    # Read training directory\n",
    "    for filename in sorted(os.listdir(train_dir)):\n",
    "        if filename.endswith(\"_masked.jpg\"):\n",
    "            combined_files.append((train_dir, filename))\n",
    "\n",
    "    # Read validation directory\n",
    "    for filename in sorted(os.listdir(validation_dir)):\n",
    "        if filename.endswith(\"_masked.jpg\"):\n",
    "            combined_files.append((validation_dir, filename))\n",
    "\n",
    "    return combined_files"
   ],
   "id": "4f3837678b7370f7",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prepare Training Data\n",
    "\n",
    "Extracts features (surrounding pixel coordinates) and targets (pixel values) from the training dataset for use in regression."
   ],
   "id": "77178b652c9e7a67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.455179Z",
     "start_time": "2025-01-05T10:52:02.447265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_training_data(train_dir):\n",
    "    \"\"\"\n",
    "    Prepares training data by extracting surrounding pixel coordinates and\n",
    "    their RGB values as features. Targets are the mean RGB color of the black region.\n",
    "    \"\"\"\n",
    "    features = [[] for _ in range(4)]  # List of lists to store features for 4 subregions\n",
    "    targets = [[] for _ in range(4)]  # List of lists to store targets for 4 subregions\n",
    "\n",
    "    for filename in sorted(os.listdir(train_dir)):\n",
    "        if filename.endswith(\"_masked.jpg\"):\n",
    "            masked_image_path = os.path.join(train_dir, filename)\n",
    "            original_image_path = masked_image_path.replace(\"_masked\", \"\")\n",
    "\n",
    "            # Load and normalize images\n",
    "            masked_image = Image.open(masked_image_path).convert(\"RGB\")\n",
    "            original_image = Image.open(original_image_path).convert(\"RGB\")\n",
    "            original_array = np.array(original_image).astype(np.float32) / 255.0\n",
    "            mask_array = np.array(masked_image).astype(np.float32) / 255.0\n",
    "            \n",
    "            y_min, y_max, x_min, x_max = find_black_rectangle(mask_array)\n",
    "            subregions = split_region(x_min, y_min, x_max, y_max)\n",
    "            \n",
    "            # Calculate mean RGB color and center coordinates for each subregion\n",
    "            subregions_means = []\n",
    "            mean_colors = []\n",
    "            for sub_x_start, sub_y_start, sub_x_end, sub_y_end in subregions:\n",
    "                region = original_array[sub_y_start:sub_y_end, sub_x_start:sub_x_end]\n",
    "                mean_colors.append(region.mean(axis=(0, 1)))  # Mean RGB (R, G, B)\n",
    "                \n",
    "                x_center = (sub_x_start + sub_x_end) / 2\n",
    "                y_center = (sub_y_start + sub_y_end) / 2\n",
    "                subregions_means.append((x_center, y_center))\n",
    "            \n",
    "            # Extract surrounding pixel coordinates and color\n",
    "            for x in range(x_min - 1, x_max + 2):\n",
    "                for y in range(y_min - 1, y_max + 2):\n",
    "                    if 0 <= x < original_array.shape[1] and 0 <= y < original_array.shape[0]:\n",
    "                        if not (x_min <= x < x_max and y_min <= y < y_max):\n",
    "                            # Find the closest subregion\n",
    "                            distances = [\n",
    "                                math.sqrt((x_center - x) ** 2 + (y_center - y) ** 2)\n",
    "                                for x_center, y_center in subregions_means\n",
    "                            ]\n",
    "                            closest_region = np.argmin(distances)\n",
    "                            \n",
    "                            # Append feature and target to the corresponding subregion\n",
    "                            features[closest_region].append([x, y])\n",
    "                            targets[closest_region].append(mean_colors[closest_region])\n",
    "\n",
    "    # Convert lists of lists into NumPy arrays\n",
    "    features = [np.array(f) for f in features]\n",
    "    targets = [np.array(t) for t in targets]\n",
    "\n",
    "    return features, targets"
   ],
   "id": "f9caaf2844a6885b",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train Regression Model\n",
    "\n",
    "Trains a linear regression model using the prepared training data."
   ],
   "id": "358be0b272a2bd8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.483746Z",
     "start_time": "2025-01-05T10:52:02.478171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_regression_model(features, targets, num_iters, learning_rate):\n",
    "    \"\"\"\n",
    "    Trains separate linear regression models for each RGB channel\n",
    "    across all subregions. Returns the weights for each channel.\n",
    "    \"\"\"\n",
    "    # Initialize weights dictionaries for RGB channels\n",
    "    weights_r = []\n",
    "    weights_g = []\n",
    "    weights_b = []\n",
    "\n",
    "    # Loop through each subregion\n",
    "    for region_idx in range(len(features)):\n",
    "        # Extract features and targets for the current subregion\n",
    "        features_region = features[region_idx]\n",
    "        targets_region = targets[region_idx]\n",
    "\n",
    "        # Separate RGB channels for the current subregion\n",
    "        targets_r = targets_region[:, 0]\n",
    "        targets_g = targets_region[:, 1]\n",
    "        targets_b = targets_region[:, 2]\n",
    "\n",
    "        # Train weights for each channel\n",
    "        weights_r.append(train_weight(features_region, targets_r, num_iters, learning_rate))\n",
    "        weights_g.append(train_weight(features_region, targets_g, num_iters, learning_rate))\n",
    "        weights_b.append(train_weight(features_region, targets_b, num_iters, learning_rate))\n",
    "\n",
    "    return weights_r, weights_g, weights_b"
   ],
   "id": "408775b30980f14",
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": [
    "def train_weight(features, targets, num_iters, learning_rate): \n",
    "    # Separate the features into x and y\n",
    "    x_features = features[:, 0:1]\n",
    "    y_features = features[:, 1:2]\n",
    "\n",
    "    # Number of input features (1 for both x and y)\n",
    "    n_in_x = x_features.shape[1]  # 1 feature for x\n",
    "    n_in_y = y_features.shape[1]  # 1 feature for y\n",
    "\n",
    "    # He Normal Initialization: standard deviation = sqrt(2 / n_in)\n",
    "    stddev_x = np.sqrt(2 / n_in_x)\n",
    "    stddev_y = np.sqrt(2 / n_in_y)\n",
    "\n",
    "    # Initialize weights using He Normal Initialization (mean = 0, stddev = sqrt(2 / n_in))\n",
    "    weight_x = np.random.normal(0, stddev_x, size=(1, 1))  # Shape (1, 1)\n",
    "    weight_y = np.random.normal(0, stddev_y, size=(1, 1))  # Shape (1, 1)\n",
    "\n",
    "    # Apply sigmoid scaling to ensure weights are between 0 and 1\n",
    "    weight_x = 1 / (1 + np.exp(-weight_x))  # Sigmoid function to scale to [0, 1]\n",
    "    weight_y = 1 / (1 + np.exp(-weight_y))  # Sigmoid function to scale to [0, 1]\n",
    "\n",
    "    for iteration in range(num_iters):\n",
    "        # Predictions for x and y components independently\n",
    "        predictions_x = (x_features @ weight_x).flatten() / 255\n",
    "        predictions_y = (y_features @ weight_y).flatten() / 255\n",
    "\n",
    "        # Combine predictions for the final output\n",
    "        predictions = predictions_x + predictions_y\n",
    "\n",
    "        # Gradients for x and y (calculated independently)\n",
    "        gradient_x = -(2 / len(x_features)) * (x_features.T @ (targets - predictions)) / 255\n",
    "        gradient_y = -(2 / len(y_features)) * (y_features.T @ (targets - predictions)) / 255\n",
    "\n",
    "        # Update weights independently\n",
    "        weight_x -= learning_rate * gradient_x\n",
    "        weight_y -= learning_rate * gradient_y\n",
    "\n",
    "    # Combine weights into a single (2, 1) matrix by stacking vertically\n",
    "    final_weight = np.vstack((weight_x, weight_y))  # Shape (2, 1)\n",
    "    \n",
    "    return final_weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.510126Z",
     "start_time": "2025-01-05T10:52:02.504456Z"
    }
   },
   "id": "2d0457b0a47d3f52",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate Reconstruction\n",
    "\n",
    "Compares reconstructed images to the original images using mean squared error (MSE) and mean absolute error (MAE)."
   ],
   "id": "7cd9834345053295"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.534438Z",
     "start_time": "2025-01-05T10:52:02.530453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_reconstruction(original, reconstructed):\n",
    "    \"\"\"\n",
    "    Computes MSE and MAE between the original and reconstructed images.\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(original.flatten(), reconstructed.flatten())\n",
    "    mae = mean_absolute_error(original.flatten(), reconstructed.flatten())\n",
    "    return mse, mae"
   ],
   "id": "dc774849fc427a08",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Process Test Dataset\n",
    "\n",
    "Processes a directory of images by identifying and reconstructing masked regions."
   ],
   "id": "c459e616401e4978"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.564944Z",
     "start_time": "2025-01-05T10:52:02.556473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_test_data(test_dir, weights_r, weights_g, weights_b):\n",
    "    \"\"\"\n",
    "    Processes test images and reconstructs black regions using the trained model.\n",
    "    Splits the black region into 4 subregions and reconstructs each separately.\n",
    "    \"\"\"\n",
    "    original_images = []\n",
    "    masked_images = []\n",
    "    reconstructed_images = []\n",
    "\n",
    "    for filename in sorted(os.listdir(test_dir)):\n",
    "        if filename.endswith(\"_masked.jpg\"):\n",
    "            masked_image_path = os.path.join(test_dir, filename)\n",
    "            original_image_path = masked_image_path.replace(\"_masked\", \"\")\n",
    "\n",
    "            masked_image = Image.open(masked_image_path).convert(\"RGB\") # New \n",
    "            original_image = Image.open(original_image_path).convert(\"RGB\") # New \n",
    "            \n",
    "            # Convert images to NumPy arrays\n",
    "            original_array = np.array(original_image).astype(np.float32) / 255.0 # New \n",
    "            mask_array = np.array(masked_image).astype(np.float32) / 255.0 # New \n",
    "            \n",
    "            y_min, y_max, x_min, x_max = find_black_rectangle(mask_array) # New\n",
    "\n",
    "            reconstructed_image = mask_array.copy() # New\n",
    "\n",
    "            # Split black region into 4 subregions\n",
    "            subregions = split_region(x_min, y_min, x_max, y_max, num_splits=4) # New\n",
    "            for sub_x_start, sub_y_start, sub_x_end, sub_y_end in subregions:\n",
    "                i = 0 # New\n",
    "                # Extract surrounding pixels\n",
    "                surrounding_pixels = []\n",
    "                for x in range(sub_x_start - 1, sub_x_end + 2):\n",
    "                    for y in range(sub_y_start - 1, sub_y_end + 2):\n",
    "                        if (\n",
    "                            0 <= x < mask_array.shape[1] # New\n",
    "                            and 0 <= y < mask_array.shape[0] # New\n",
    "                        ):\n",
    "                            if not (sub_x_start <= x < sub_x_end and sub_y_start <= y < sub_y_end):\n",
    "                                surrounding_pixels.append([x, y])\n",
    "\n",
    "                surrounding_pixels = np.array(surrounding_pixels)\n",
    "\n",
    "                # Predict mean RGB color for the subregion\n",
    "                if surrounding_pixels.size > 0:  # Ensure non-empty surrounding pixels\n",
    "                    mean_r = np.dot(surrounding_pixels, weights_r[i]).mean() # New\n",
    "                    mean_g = np.dot(surrounding_pixels, weights_g[i]).mean() # New\n",
    "                    mean_b = np.dot(surrounding_pixels, weights_b[i]).mean() # New\n",
    "                else:\n",
    "                    mean_r, mean_g, mean_b = 0, 0, 0  # Default to black if no context\n",
    "                \n",
    "                mean_r, mean_g, mean_b = mean_r / 255, mean_g / 255, mean_b / 255\n",
    "                \n",
    "                # Ensure proper RGB assignment\n",
    "                reconstructed_image[sub_y_start:sub_y_end, sub_x_start:sub_x_end, 0] = mean_r # Red\n",
    "                reconstructed_image[sub_y_start:sub_y_end, sub_x_start:sub_x_end, 1] = mean_g # Green\n",
    "                reconstructed_image[sub_y_start:sub_y_end, sub_x_start:sub_x_end, 2] = mean_b # Blue\n",
    "            \n",
    "                i += 1 # New\n",
    "            \n",
    "            original_images.append(original_array)\n",
    "            masked_images.append(mask_array)\n",
    "            reconstructed_images.append(reconstructed_image)\n",
    "\n",
    "    return original_images, masked_images, reconstructed_images"
   ],
   "id": "520803bfaff4a11e",
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "def reconstruct_reference(reference_dir, weights_r, weights_g, weights_b):\n",
    "    masked_images = []\n",
    "    reconstructed_images = []\n",
    "    \n",
    "    for filename in sorted(os.listdir(reference_dir)):\n",
    "        if filename.endswith(\"_masked.jpg\"):\n",
    "            masked_image_path = os.path.join(reference_dir, filename)\n",
    "            masked_image = Image.open(masked_image_path).convert(\"RGB\")\n",
    "            mask_array = np.array(masked_image).astype(np.float32) / 255.0\n",
    "            \n",
    "            y_min, y_max, x_min, x_max = find_black_rectangle(mask_array)\n",
    "\n",
    "            reconstructed_image = mask_array.copy()\n",
    "            \n",
    "            # Split black region into 4 subregions\n",
    "            subregions = split_region(x_min, y_min, x_max, y_max, num_splits=4) # New\n",
    "            for sub_x_start, sub_y_start, sub_x_end, sub_y_end in subregions:\n",
    "                i = 0 # New\n",
    "                # Extract surrounding pixels\n",
    "                surrounding_pixels = []\n",
    "                for x in range(sub_x_start - 1, sub_x_end + 2):\n",
    "                    for y in range(sub_y_start - 1, sub_y_end + 2):\n",
    "                        if (\n",
    "                            0 <= x < mask_array.shape[1] # New\n",
    "                            and 0 <= y < mask_array.shape[0] # New\n",
    "                        ):\n",
    "                            if not (sub_x_start <= x < sub_x_end and sub_y_start <= y < sub_y_end):\n",
    "                                surrounding_pixels.append([x, y])\n",
    "\n",
    "                surrounding_pixels = np.array(surrounding_pixels)\n",
    "\n",
    "                # Predict mean RGB color for the subregion\n",
    "                if surrounding_pixels.size > 0:  # Ensure non-empty surrounding pixels\n",
    "                    mean_r = np.dot(surrounding_pixels, weights_r[i]).mean() # New\n",
    "                    mean_g = np.dot(surrounding_pixels, weights_g[i]).mean() # New\n",
    "                    mean_b = np.dot(surrounding_pixels, weights_b[i]).mean() # New\n",
    "                else:\n",
    "                    mean_r, mean_g, mean_b = 0, 0, 0  # Default to black if no context\n",
    "                \n",
    "                mean_r, mean_g, mean_b = mean_r / 255, mean_g / 255, mean_b / 255\n",
    "                                \n",
    "                # Ensure proper RGB assignment\n",
    "                reconstructed_image[sub_y_start:sub_y_end, sub_x_start:sub_x_end, 0] = mean_r # Red\n",
    "                reconstructed_image[sub_y_start:sub_y_end, sub_x_start:sub_x_end, 1] = mean_g # Green\n",
    "                reconstructed_image[sub_y_start:sub_y_end, sub_x_start:sub_x_end, 2] = mean_b # Blue\n",
    "            \n",
    "                i += 1 # New\n",
    "            \n",
    "            masked_images.append(mask_array)\n",
    "            reconstructed_images.append(reconstructed_image)\n",
    "            \n",
    "    return masked_images, reconstructed_images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.593297Z",
     "start_time": "2025-01-05T10:52:02.585874Z"
    }
   },
   "id": "5a66f77f31b8e2b2",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Display Results\n",
    "\n",
    "Displays the masked and reconstructed images side by side for visual comparison."
   ],
   "id": "3243cb5ca0de5608"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:52:02.640573Z",
     "start_time": "2025-01-05T10:52:02.634954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def display_results(masked_images, reconstructed_images):\n",
    "    \"\"\"\n",
    "    Displays masked and reconstructed images in a grid layout for comparison.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(15, 12)) # New\n",
    "\n",
    "    for i in range(10):\n",
    "        if i < 5:\n",
    "            axs[0, i].imshow(masked_images[i])\n",
    "            axs[0, i].axis(\"off\")\n",
    "            axs[0, i].set_title(f\"Masked {i+1}\", fontsize=16)\n",
    "\n",
    "            axs[1, i].imshow(reconstructed_images[i])\n",
    "            axs[1, i].axis(\"off\")\n",
    "            axs[1, i].set_title(f\"Prediction {i+1}\", fontsize=16)\n",
    "\n",
    "        else:\n",
    "            axs[2, i - 5].imshow(masked_images[i])\n",
    "            axs[2, i - 5].axis(\"off\")\n",
    "            axs[2, i - 5].set_title(f\"Masked {i+1}\", fontsize=16)\n",
    "\n",
    "            axs[3, i - 5].imshow(reconstructed_images[i])\n",
    "            axs[3, i - 5].axis(\"off\")\n",
    "            axs[3, i - 5].set_title(f\"Prediction {i+1}\", fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "6f9c555175f52277",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Run the Reconstruction Workflow\n",
    "\n",
    "Combines all functions to train the model using the training dataset and reconstruct masked regions in the test dataset."
   ],
   "id": "a593fb33edb53b77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:26:31.679477Z",
     "start_time": "2025-01-05T10:52:02.649551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Base directory for the dataset\n",
    "base_dir = os.path.join(\"..\", \"Dataset\")\n",
    "\n",
    "# Directories for train, validation, and test sets\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"validation\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "reference_dir = os.path.join(\"..\", \"Reference_Images\")\n",
    "\n",
    "features, targets = prepare_training_data(train_dir)\n",
    "\n",
    "num_iterations = 30000\n",
    "learning_rate = 0.001\n",
    "\n",
    "weights_r, weights_g, weights_b = train_regression_model(features, targets, num_iterations, learning_rate)\n",
    "\n",
    "# Process test dataset\n",
    "original_images, masked_images, reconstructed_images = process_test_data(\n",
    "    test_dir, weights_r, weights_g, weights_b\n",
    ")\n",
    "\n",
    "# Convert reconstructed and test images back to [0, 255] range\n",
    "unnormalized_reconstructed_images = [\n",
    "    (reconstructed_image * 255.0).astype(np.float32) for reconstructed_image in reconstructed_images\n",
    "]\n",
    "unnormalized_test_images = [\n",
    "    (test_image * 255.0).astype(np.float32) for test_image in original_images\n",
    "]\n",
    "\n",
    "# Initialize lists to store MSE and MAE for each image pair\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "\n",
    "# Calculate MSE and MAE for each image pair\n",
    "for original, reconstructed in zip(unnormalized_test_images, unnormalized_reconstructed_images):\n",
    "    mse, mae = evaluate_reconstruction(original, reconstructed)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "\n",
    "\n",
    "# Compute average MSE and MAE across all image pairs\n",
    "average_mse = np.mean(mse_list)\n",
    "average_mae = np.mean(mae_list)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Linear Regression MSE: {average_mse:.4f}\")\n",
    "print(f\"Linear Regression MAE: {average_mae:.4f}\")\n",
    "\n",
    "\n",
    "# Process reference images\n",
    "masked_reference, reconstructed_reference = reconstruct_reference(\n",
    "    reference_dir, weights_r, weights_g, weights_b\n",
    ")\n",
    "\n",
    "# Display results\n",
    "display_results(masked_reference, reconstructed_reference)"
   ],
   "id": "e7f6f3d39f263cdb",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[80], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m num_iterations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m30000\u001B[39m\n\u001B[0;32m     13\u001B[0m learning_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.001\u001B[39m\n\u001B[1;32m---> 15\u001B[0m weights_r, weights_g, weights_b \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_regression_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_iterations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Process test dataset\u001B[39;00m\n\u001B[0;32m     18\u001B[0m original_images, masked_images, reconstructed_images \u001B[38;5;241m=\u001B[39m process_test_data(\n\u001B[0;32m     19\u001B[0m     test_dir, weights_r, weights_g, weights_b\n\u001B[0;32m     20\u001B[0m )\n",
      "Cell \u001B[1;32mIn[74], line 24\u001B[0m, in \u001B[0;36mtrain_regression_model\u001B[1;34m(features, targets, num_iters, learning_rate)\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# Train weights for each channel\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     weights_r\u001B[38;5;241m.\u001B[39mappend(train_weight(features_region, targets_r, num_iters, learning_rate))\n\u001B[1;32m---> 24\u001B[0m     weights_g\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtrain_weight\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures_region\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets_g\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_iters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     25\u001B[0m     weights_b\u001B[38;5;241m.\u001B[39mappend(train_weight(features_region, targets_b, num_iters, learning_rate))\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m weights_r, weights_g, weights_b\n",
      "Cell \u001B[1;32mIn[75], line 25\u001B[0m, in \u001B[0;36mtrain_weight\u001B[1;34m(features, targets, num_iters, learning_rate)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m iteration \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_iters):\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;66;03m# Predictions for x and y components independently\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     predictions_x \u001B[38;5;241m=\u001B[39m (x_features \u001B[38;5;241m@\u001B[39m weight_x)\u001B[38;5;241m.\u001B[39mflatten() \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255\u001B[39m\n\u001B[1;32m---> 25\u001B[0m     predictions_y \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43my_features\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mweight_y\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255\u001B[39m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;66;03m# Combine predictions for the final output\u001B[39;00m\n\u001B[0;32m     28\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m predictions_x \u001B[38;5;241m+\u001B[39m predictions_y\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
