{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset Preparation and Masking Tool\n",
    "\n",
    "This notebook prepares a dataset for image reconstruction using a GAN model by applying random rectangular masks to images and organizing the dataset into train, validation, and test splits. The goal is to ensure that each split contains a balanced representation of each class.\n",
    "\n",
    "## Overview\n",
    "The notebook:\n",
    "1. **Applies Random Rectangular Masks**: Adds a black rectangular mask at a random position on each image. The mask size is randomly chosen within a specified range.\n",
    "2. **Organizes Dataset into Splits**: Splits the dataset into train, validation, and test sets, ensuring that each set contains a proportional distribution of each class (stratified sampling).\n",
    "3. **Names Images Consistently**: Saves each original image and its corresponding masked version with a consistent naming convention, making it easy for the GAN model to pair original and masked images during training.\n",
    "\n",
    "## Parameters\n",
    "- `source_dir`: Path to the original dataset directory containing subdirectories for each class.\n",
    "- `target_dir`: Path where the processed dataset will be saved, organized into train, validation, and test directories.\n",
    "- `min_mask_size` and `max_mask_size`: Range for the rectangular mask dimensions (height and width).\n",
    "- `test_split` and `val_split`: Proportions of the dataset allocated to the test and validation sets, respectively. The remaining portion is used for training.\n",
    "\n",
    "## Execution\n",
    "After setting the parameters, execute the final cell to process the dataset. This will:\n",
    "- Apply masks to each image in the specified directory.\n",
    "- Save both the original and masked images in the train, validation, and test directories within `target_dir`.\n",
    "- Ensure each split has a balanced mix of classes and a consistent naming scheme.\n",
    "\n",
    "The final dataset will be structured and ready for training in an image reconstruction task using a GAN model."
   ],
   "id": "fb9ce3452443c412"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "e4a293b09dff8690"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T07:35:00.388199Z",
     "start_time": "2024-11-12T07:35:00.385087Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set Parameters",
   "id": "4ef020f3b101f668"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:35:00.400891Z",
     "start_time": "2024-11-12T07:35:00.396686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the current working directory in a Jupyter notebook\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define source and target directories based on the current file location\n",
    "source_dir = os.path.join(current_dir, \"imagenet_selected_raw_classes\")\n",
    "target_dir = os.path.join(current_dir, \"..\", \"Dataset\")  # Moves one level up and creates 'Dataset' directory\n",
    "\n",
    "min_mask_size = 30                        # Minimum dimension for the rectangular mask\n",
    "max_mask_size = 60                       # Maximum dimension for the rectangular mask\n",
    "\n",
    "# Split ratios\n",
    "test_split = 0.2                          # Fraction of data for the test set\n",
    "val_split = 0.1                           # Fraction of data for the validation set (from remaining data)\n",
    "\n",
    "image_size = 224                          # Size of the images for the GAN model"
   ],
   "id": "b43803c2e4b5064d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset Processing with Stratified Split and Random Rectangle Mask\n",
    "\n",
    "This section processes a dataset by creating train, validation, and test splits that evenly represent each class.\n",
    "A random rectangular mask is applied to each image, saving both the original and masked versions in the target directory."
   ],
   "id": "aeede72010a56561"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Masking Function",
   "id": "c7a77df1f9373302"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:35:00.412287Z",
     "start_time": "2024-11-12T07:35:00.408095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_random_rectangle_mask(image, min_mask_size=30, max_mask_size=60):\n",
    "    \"\"\"\n",
    "    Applies a black rectangular mask of random size within a specified range at a random location on an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image (PIL.Image.Image): The image object to be masked.\n",
    "    - min_mask_size (int): Minimum dimension for the rectangular mask (height and width).\n",
    "    - max_mask_size (int): Maximum dimension for the rectangular mask (height and width).\n",
    "    \n",
    "    Returns:\n",
    "    - masked_image (PIL.Image.Image): Image with a black rectangular mask applied.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy of the image to avoid modifying the original\n",
    "    masked_image = image.copy()\n",
    "    width, height = masked_image.size\n",
    "\n",
    "    # Randomly determine the rectangle width and height within the given range\n",
    "    rect_width = random.randint(min_mask_size, max_mask_size)\n",
    "    rect_height = random.randint(min_mask_size, max_mask_size)\n",
    "\n",
    "    # Generate random coordinates for the top-left corner of the rectangle\n",
    "    x = random.randint(0, width - rect_width)\n",
    "    y = random.randint(0, height - rect_height)\n",
    "\n",
    "    # Draw the black rectangle mask\n",
    "    draw = ImageDraw.Draw(masked_image)\n",
    "    draw.rectangle([x, y, x + rect_width, y + rect_height], fill=\"black\")\n",
    "    \n",
    "    return masked_image"
   ],
   "id": "f06f76b9d99a526d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset Processing with Stratified Splits",
   "id": "62c1f8a6f78c2170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:35:00.431635Z",
     "start_time": "2024-11-12T07:35:00.424094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_dataset_with_stratified_splits(source_dir, target_dir, min_mask_size=30, max_mask_size=60, test_split=0.2, val_split=0.1, image_size=224):\n",
    "    \"\"\"\n",
    "    Processes a dataset by applying a black rectangular mask to each image, renaming them by class,\n",
    "    and organizing them into stratified train, validation, and test splits.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_dir (str): Directory containing the original dataset with subdirectories for each class.\n",
    "    - target_dir (str): Directory to save the processed dataset.\n",
    "    - min_mask_size (int): Minimum dimension for the rectangular mask (height and width).\n",
    "    - max_mask_size (int): Maximum dimension for the rectangular mask (height and width).\n",
    "    - test_split (float): Fraction of data to reserve for testing.\n",
    "    - val_split (float): Fraction of data to reserve for validation (from the remaining training data).\n",
    "    \"\"\"\n",
    "    # Create directories for train, validation, and test\n",
    "    train_dir = os.path.join(target_dir, \"train\")\n",
    "    val_dir = os.path.join(target_dir, \"validation\")\n",
    "    test_dir = os.path.join(target_dir, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Collect all images by class\n",
    "    train_images, val_images, test_images = [], [], []\n",
    "\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        class_dir = os.path.join(source_dir, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue  # Skip if it's not a directory\n",
    "\n",
    "        # Gather all image paths in the class subdirectory\n",
    "        image_paths = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        # Stratified split into train, validation, and test for this class\n",
    "        train_paths, temp_paths = train_test_split(image_paths, test_size=(test_split + val_split), random_state=42)\n",
    "        val_paths, test_paths = train_test_split(temp_paths, test_size=test_split / (test_split + val_split), random_state=42)\n",
    "\n",
    "        # Append to overall lists with a consistent naming format\n",
    "        train_images += [(path, class_name, i) for i, path in enumerate(train_paths)]\n",
    "        val_images += [(path, class_name, i) for i, path in enumerate(val_paths)]\n",
    "        test_images += [(path, class_name, i) for i, path in enumerate(test_paths)]\n",
    "    \n",
    "    # Process and save images in each split\n",
    "    for image_path, class_name, index in train_images:\n",
    "        save_image_pair(image_path, train_dir, class_name, index, min_mask_size, max_mask_size)\n",
    "\n",
    "    for image_path, class_name, index in val_images:\n",
    "        save_image_pair(image_path, val_dir, class_name, index, min_mask_size, max_mask_size)\n",
    "\n",
    "    for image_path, class_name, index in test_images:\n",
    "        save_image_pair(image_path, test_dir, class_name, index, min_mask_size, max_mask_size)"
   ],
   "id": "954286f2ccd958c9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save Image Pairs Function",
   "id": "1d382f2c5ddc0ccb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:35:00.446040Z",
     "start_time": "2024-11-12T07:35:00.441267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_image_pair(image_path, save_dir, class_name, index, min_mask_size=30, max_mask_size=60, image_size=224):\n",
    "    \"\"\"\n",
    "    Saves the original and masked versions of an image with a consistent naming convention, resizing each to a specified size.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path (str): Path to the original image file.\n",
    "    - save_dir (str): Directory where the processed images will be saved.\n",
    "    - class_name (str): Name of the class to prefix the filenames.\n",
    "    - index (int): Index of the image in its class for unique naming.\n",
    "    - min_mask_size (int): Minimum size of the mask.\n",
    "    - max_mask_size (int): Maximum size of the mask.\n",
    "    - image_size (int): Size to which the image will be resized (width and height).\n",
    "    \"\"\"\n",
    "    # Define unique names for the original and masked images\n",
    "    base_filename = f\"{class_name}_{index:03d}\"\n",
    "    original_save_path = os.path.join(save_dir, f\"{base_filename}.jpg\")\n",
    "    masked_save_path = os.path.join(save_dir, f\"{base_filename}_masked.jpg\")\n",
    "    \n",
    "    # Open and resize the original image\n",
    "    original_image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_image = original_image.resize((image_size, image_size))\n",
    "    original_image.save(original_save_path)\n",
    "    \n",
    "    # Apply mask and save masked image\n",
    "    masked_image = apply_random_rectangle_mask(original_image, min_mask_size, max_mask_size)\n",
    "    masked_image.save(masked_save_path)"
   ],
   "id": "c915cdc147b128a1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run Dataset Processing",
   "id": "3a144af0fe3fe4ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:36:54.298874Z",
     "start_time": "2024-11-12T07:35:00.453415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the dataset processing with the specified parameters\n",
    "process_dataset_with_stratified_splits(\n",
    "    source_dir=source_dir,\n",
    "    target_dir=target_dir,\n",
    "    min_mask_size=min_mask_size,\n",
    "    max_mask_size=max_mask_size,\n",
    "    test_split=test_split,\n",
    "    val_split=val_split,\n",
    "    image_size=image_size\n",
    ")"
   ],
   "id": "767a474009bb2f7b",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
